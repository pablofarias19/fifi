# -*- coding: utf-8 -*-
"""
CONFIGURACI√ìN CENTRALIZADA - Sistema RAG Jur√≠dico-Sanitario
------------------------------------------------------------
Configuraci√≥n √∫nica para embeddings, rutas, modelos y par√°metros.
Elimina duplicaciones y asegura consistencia en todo el proyecto.
"""

import os
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict

# ======================
# RUTAS PRINCIPALES
# ======================

ROOT = Path(__file__).parent
PDF_DIR_DEFAULT = ROOT / "pdfs"
DB_DIR_DEFAULT = ROOT / "chroma_db_legal"
CACHE_DIR_DEFAULT = ROOT / "chroma_cache"
LOGS_DIR = ROOT / "logs"
PROMPTS_DIR = ROOT / "prompts"
REGISTRY_PATH = DB_DIR_DEFAULT / "registry.json"

# Asegurar que existen
for d in [PDF_DIR_DEFAULT, DB_DIR_DEFAULT, CACHE_DIR_DEFAULT, LOGS_DIR, PROMPTS_DIR]:
    d.mkdir(exist_ok=True)

# ======================
# EMBEDDINGS - CONFIGURACI√ìN √öNICA
# ======================

# Modelo est√°ndar para TODO el proyecto
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
EMBEDDING_DIMENSION = 768

# Modelos soportados (para migraciones)
SUPPORTED_MODELS = {
    "sentence-transformers/all-MiniLM-L6-v2": 384,
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2": 384,
    "sentence-transformers/all-mpnet-base-v2": 768,
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2": 768,
}

# ======================
# BASES RAG DISPONIBLES
# ======================

BASES_RAG: Dict[str, str] = {
    "Salud - M√©dica": "pdfs_salud_medica",
    "Salud - Laboral": "pdfs_salud_laboral",
    "Jurisprudencia - Salud": "pdfs_jurisprud_salud",
    "Legislaci√≥n - Salud": "pdfs_ley_salud",
}

# ======================
# LLM (GEMINI)
# ======================

DEFAULT_LLM = "gemini-2.5-pro"
DEFAULT_TEMPERATURE = 0.2

# ======================
# PROMPTS DE AN√ÅLISIS
# ======================

PROMPT_ANALISIS_PATH = PROMPTS_DIR / "analisis_salud.md"

DEFAULT_ANALYSIS_PROMPT = """[Contexto recuperado con metadatos y referencias]
{contexto}

[Texto o consulta principal]
{texto}

[INSTRUCCIONES DE AN√ÅLISIS]
1Ô∏è‚É£ **S√≠ntesis contextual**
   - Resume el caso y su contexto jur√≠dico-m√©dico.
   - Determina tipo de responsabilidad (civil, penal, laboral, bio√©tica).
   - Reconoce las fuentes primarias y secundarias relevantes.

2Ô∏è‚É£ **Ejes conceptuales**
   - Desarrolla los temas: consentimiento informado, lex artis, causalidad, da√±o, prueba.
   - Para cada eje: explica el concepto, cita fuentes con autor/a√±o/p√°gina o tribunal/a√±o.
   - Usa las referencias documentales para sostener los razonamientos.

3Ô∏è‚É£ **Evaluaci√≥n argumental**
   - Se√±ala los argumentos m√°s s√≥lidos y las debilidades.
   - Indica contradicciones entre jurisprudencias o doctrinas.
   - Identifica lagunas normativas o probatorias.

4Ô∏è‚É£ **Fuentes y trazabilidad**
   - Crea una lista de fuentes relevantes con formato:
     "Autor ‚Äì T√≠tulo (A√±o), p√°g. X [URL o Jurisdicci√≥n]"
   - Indica si son doctrina, jurisprudencia o normativa.
   - Recomienda cu√°les podr√≠an ampliarse con consultas espec√≠ficas o documentos adicionales.

5Ô∏è‚É£ **Preguntas derivadas**
   - Formula 3 a 5 preguntas que profundicen el an√°lisis.
   - Indica qu√© informaci√≥n o tipo de documento ser√≠a necesario obtener para resolverlas.

6Ô∏è‚É£ **Conclusi√≥n jur√≠dica**
   - Formula una tesis integrada, valorando la probabilidad de √©xito (baja/media/alta).
   - Justifica con criterios jur√≠dicos y m√©dicos.

[FORMATO DE SALIDA]
Primero entrega un informe narrativo completo con secciones jerarquizadas:
üîπ Resumen contextual
üîπ Ejes conceptuales
üîπ Debilidades / Vac√≠os argumentales
üîπ Preguntas de profundizaci√≥n
üîπ Conclusi√≥n jur√≠dica y fuentes

Luego, entrega un bloque JSON resumido con esta estructura:

{{
  "tesis": "...",
  "conceptos_clave": ["..."],
  "debilidades": ["..."],
  "preguntas": ["..."],
  "probabilidad_exito": "baja|media|alta",
  "fuentes_relevantes": [
    {{"autor": "...", "titulo": "...", "anio": "...", "pagina": "...", "url": "...", "tipo": "..."}}
  ]
}}
"""


def get_analysis_prompt(path: Path = PROMPT_ANALISIS_PATH, default: str = DEFAULT_ANALYSIS_PROMPT) -> str:
    """Retorna el prompt de an√°lisis, permitiendo sobrescribirlo mediante archivo."""

    # Permite sobreescribir la ruta v√≠a variable de entorno.
    env_override = os.environ.get("ANALYSIS_PROMPT_FILE")
    candidates = []
    if env_override:
        candidates.append(Path(env_override).expanduser())
    if path:
        candidates.append(path)

    for candidate in candidates:
        try:
            if candidate.exists():
                return candidate.read_text(encoding="utf-8")
        except OSError:
            # Ignora rutas inv√°lidas y contin√∫a con el siguiente candidato.
            continue
    return default

# ======================
# OCR
# ======================

IDIOMAS_VALIDOS = ["en", "de", "es", "fr", "it"]
LANG_TESSERACT = "spa+eng+fra+ita+deu"

# ======================
# PAR√ÅMETROS DE INGESTA
# ======================

@dataclass
class IngestaConfig:
    """Configuraci√≥n para ingesta de documentos"""
    chunk_size: int = 600
    chunk_overlap: int = 120
    usar_ocr: bool = True
    dpi_ocr: int = 300
    lang_ocr: str = LANG_TESSERACT
    min_quality_score: float = 0.30

    # Nuevos par√°metros de versionado
    auto_version: bool = True  # Auto-incrementar versi√≥n en cambios
    create_backup: bool = True  # Backup antes de modificar

    # Par√°metros de extracci√≥n de metadata
    detect_language: bool = True           # Detectar idioma autom√°ticamente
    extract_author: bool = True            # Intentar extraer autor
    extract_title: bool = True             # Intentar extraer t√≠tulo
    extract_year: bool = True              # Intentar extraer a√±o
    extract_jurisdiction: bool = True      # Intentar extraer jurisdicci√≥n
    use_llm_metadata: bool = False         # Usar Gemini para extraer metadata (lento pero preciso)
    llm_metadata_sample_size: int = 3000   # Tama√±o de muestra de texto para LLM

# ======================
# PAR√ÅMETROS DE AN√ÅLISIS
# ======================

@dataclass
class AnalysisConfig:
    """Configuraci√≥n para an√°lisis RAG"""
    k_por_base: int = 5           # Fragmentos a recuperar por base
    fetch_k: int = 32              # Candidatos para re-ranking
    max_context_length: int = 8000 # Longitud m√°xima de contexto

    # Re-scoring
    enable_rescoring: bool = True
    keyword_bonus_max: float = 0.20
    structure_bonus: float = 0.05
    quality_bonus_max: float = 0.10

# ======================
# KEYWORDS JUR√çDICO-SANITARIAS
# ======================

KEYWORDS_JURIDICO_SANIT = (
    "art√≠culo", "articulo", "considerando", "resuelve", "sentencia", "fallo",
    "tribunal", "c√°mara", "juzgado", "demanda", "dictamen",
    "consentimiento informado", "historia cl√≠nica", "lex artis", "mala praxis",
    "paciente", "responsabilidad", "causalidad", "da√±o", "negligencia",
    "protocolo", "bio√©tica", "OMS", "OPS"
)

# ======================
# INSTANCIAS POR DEFECTO
# ======================

DEFAULT_INGESTA_CONFIG = IngestaConfig()
DEFAULT_ANALYSIS_CONFIG = AnalysisConfig()

# ======================
# SISTEMA DE VERSIONADO
# ======================

VERSION_SYSTEM = {
    "enabled": True,
    "semantic_versioning": True,  # Usa versionado sem√°ntico (MAJOR.MINOR.PATCH)
    "keep_old_versions": True,     # Mantiene versiones antiguas
    "max_versions_per_base": 3,    # M√°ximo de versiones a mantener
}
